{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "faces = fetch_lfw_people(min_faces_per_person=60)\n",
    "#print(faces.images[0])\n",
    "print(faces.target_names)\n",
    "print(faces.images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try to plot the faces from faces.images matrix and faces.target_names as labels. TIP: use subplots and imshow functions from matplotlib\n",
    "\n",
    "fig, ax = plotter.subplots(2, 1, figsize=(8, 3))\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    axi.imshow(faces.images[i], cmap='bone')\n",
    "    axi.set(xticks=[], yticks=[])\n",
    "    axi.set_ylabel(faces.target_names[faces.target[i]].split()[-1], color = \"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, metrics\n",
    "n_samples = len(faces.images)\n",
    "data = faces.images.reshape((n_samples, -1))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make pipeline of SVM and RandomizedPCA model using sklearn library (make_pipeline command).\n",
    "#TIP: use nonlinear Gaussian kernel in SVM (rbf) and number of PCA components (try 50 and 150).\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel='rbf', C=1E6)\n",
    "X, y = faces.data, faces.target\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=150)\n",
    "pca.fit(X)\n",
    "print(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we will use a principal component analysis to extract 150 fundamental components to feed into our \n",
    "#support vector machine classifier. \n",
    "#We can do this most straightforwardly by packaging the preprocessor and the classifier into a single pipeline \n",
    "#using make_pipeline function\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pca=PCA(n_components=150)\n",
    "clf=SVC(kernel='rbf', C=1E6)\n",
    "\n",
    "poly_model = make_pipeline(pca,clf)\n",
    "poly_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the sake of testing our classifier output, you have to will split the data into a training and testing set. \n",
    "#TIP: use training_test_split function from _sklearn.cross_validation_\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "#help(train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform a grid search cross-validation to explore combinations of parameters. \n",
    "#Here we will adjust C (which controls the margin hardness) and \n",
    "#gamma (which controls the size of the radial basis function kernel) in SVM, to find the best model. \n",
    "#TIP: use GridSearchCV from _sklearn.grid_search_, use following values for 'svn__c': [1, 5, 10, 50] \n",
    "#and 'svc__gamma: [0.0001, 0.0005, 0.001, 0.005]. Fit the training data to find out the parameters.\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "tuned_parameters = [{'C': [1, 5, 10, 50], 'gamma': [0.0001, 0.0005, 0.001, 0.005],'kernel': ['rbf']}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print best parameters from grid search. If The optimal values fall fell at the edges, \n",
    "#we would want to expand the grid to make sure we have found the true optimum.\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SVC(), tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % score)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))    \n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use best estimator (best_estimator_ function) from grid search to predict labels for test sample generated in 3). \n",
    "#TIP: use predict function\n",
    "help(best_estimator_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use few test images to check the fit accuracy and plot images with estimator assigned labels like in 1).\n",
    "\n",
    "clf.predict(X.test[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
